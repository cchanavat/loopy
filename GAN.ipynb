{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x256e43a4dd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"data/raw/raw_16_png\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 16\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 16\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 30\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 16\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# size of kernel\n",
    "kernel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x256ea12b910>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 2, kernel_size, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 2 x 2\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, kernel_size, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf, nc, kernel_size, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(30, 32, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(16, 3, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf, ndf * 2, 2, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 2, 1, 8, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(64, 1, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (5 x 5). Kernel size: (8 x 8). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-326-6cb95291134c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# Forward pass real batch through D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-323-c385d300c2ef>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (5 x 5). Kernel size: (8 x 8). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        print(output.shape)\n",
    "        print(b_size)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
